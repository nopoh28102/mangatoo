#!/usr/bin/env python3
"""
ØªØ­Ù„ÙŠÙ„ Ø´Ø§Ù…Ù„ Ù„Ù„Ù…Ø´Ø±ÙˆØ¹ Ù„Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø§Ù„ØªÙƒØ±Ø§Ø± ÙˆØ§Ù„ØªØ¶Ø§Ø±Ø¨ ÙÙŠ Ø§Ù„ØµÙØ­Ø§Øª ÙˆØ§Ù„Ù…Ø³Ø§Ø±Ø§Øª
"""
import os
import re
from collections import defaultdict

def analyze_routes():
    """ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø³Ø§Ø±Ø§Øª Ø§Ù„Ù…ÙƒØ±Ø±Ø©"""
    print("=== ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø³Ø§Ø±Ø§Øª ÙÙŠ routes.py ===")
    
    routes = {}
    duplicate_routes = defaultdict(list)
    
    with open('routes.py', 'r', encoding='utf-8') as f:
        content = f.read()
        
    # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ø³Ø§Ø±Ø§Øª
    route_pattern = r"@app\.route\(['\"]([^'\"]+)['\"](?:,\s*methods=\[[^\]]+\])?\)\s*\n(?:@[\w_]+\s*\n)*def\s+(\w+)"
    matches = re.finditer(route_pattern, content, re.MULTILINE)
    
    for match in matches:
        route = match.group(1)
        function_name = match.group(2)
        
        if route in routes:
            duplicate_routes[route].append({
                'existing': routes[route],
                'new': function_name
            })
        else:
            routes[route] = function_name
            
    print(f"Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ù…Ø³Ø§Ø±Ø§Øª: {len(routes)}")
    
    if duplicate_routes:
        print("\nâš ï¸ Ù…Ø³Ø§Ø±Ø§Øª Ù…ÙƒØ±Ø±Ø© Ù…Ø­ØªÙ…Ù„Ø©:")
        for route, duplicates in duplicate_routes.items():
            print(f"  {route}:")
            for dup in duplicates:
                print(f"    - {dup['existing']} / {dup['new']}")
    
    # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ù…Ø³Ø§Ø±Ø§Øª Ù…ØªØ´Ø§Ø¨Ù‡Ø©
    similar_routes = []
    route_list = list(routes.keys())
    for i, route1 in enumerate(route_list):
        for route2 in route_list[i+1:]:
            if routes_are_similar(route1, route2):
                similar_routes.append((route1, route2, routes[route1], routes[route2]))
    
    if similar_routes:
        print("\nâš ï¸ Ù…Ø³Ø§Ø±Ø§Øª Ù…ØªØ´Ø§Ø¨Ù‡Ø© Ù‚Ø¯ ØªØ³Ø¨Ø¨ ØªØ¶Ø§Ø±Ø¨:")
        for route1, route2, func1, func2 in similar_routes:
            print(f"  {route1} ({func1}) <-> {route2} ({func2})")
    
    return routes, duplicate_routes, similar_routes

def routes_are_similar(route1, route2):
    """ÙØ­Øµ Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ù…Ø³Ø§Ø±Ø§Øª Ù…ØªØ´Ø§Ø¨Ù‡Ø© Ø¨Ø´ÙƒÙ„ Ù‚Ø¯ ÙŠØ³Ø¨Ø¨ ØªØ¶Ø§Ø±Ø¨"""
    # Ø¥Ø²Ø§Ù„Ø© Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª
    clean1 = re.sub(r'<[^>]+>', '<var>', route1)
    clean2 = re.sub(r'<[^>]+>', '<var>', route2)
    
    # Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ù†Ù…Ø· Ø§Ù„Ø¹Ø§Ù…
    pattern1 = clean1.replace('<var>', '.*')
    pattern2 = clean2.replace('<var>', '.*')
    
    return (re.match(pattern1, route2) or re.match(pattern2, route1)) and route1 != route2

def analyze_templates():
    """ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù‚ÙˆØ§Ù„Ø¨ Ø§Ù„Ù…ÙƒØ±Ø±Ø©"""
    print("\n=== ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù‚ÙˆØ§Ù„Ø¨ ===")
    
    template_files = []
    template_names = defaultdict(list)
    
    # Ø¬Ù…Ø¹ Ø¬Ù…ÙŠØ¹ Ù…Ù„ÙØ§Øª HTML
    for root, dirs, files in os.walk('templates'):
        for file in files:
            if file.endswith('.html'):
                full_path = os.path.join(root, file)
                template_files.append(full_path)
                template_names[file].append(full_path)
    
    print(f"Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ù…Ù„ÙØ§Øª Ø§Ù„Ù‚ÙˆØ§Ù„Ø¨: {len(template_files)}")
    
    # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø£Ø³Ù…Ø§Ø¡ Ù…ÙƒØ±Ø±Ø©
    duplicates = {name: paths for name, paths in template_names.items() if len(paths) > 1}
    
    if duplicates:
        print("\nâš ï¸ Ø£Ø³Ù…Ø§Ø¡ Ù‚ÙˆØ§Ù„Ø¨ Ù…ÙƒØ±Ø±Ø©:")
        for name, paths in duplicates.items():
            print(f"  {name}:")
            for path in paths:
                print(f"    - {path}")
    
    return template_files, duplicates

def analyze_template_content():
    """ØªØ­Ù„ÙŠÙ„ Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù‚ÙˆØ§Ù„Ø¨ Ù„Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ ØªÙƒØ±Ø§Ø±"""
    print("\n=== ØªØ­Ù„ÙŠÙ„ Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù‚ÙˆØ§Ù„Ø¨ ===")
    
    template_content = {}
    content_hashes = defaultdict(list)
    
    for root, dirs, files in os.walk('templates'):
        for file in files:
            if file.endswith('.html'):
                full_path = os.path.join(root, file)
                try:
                    with open(full_path, 'r', encoding='utf-8') as f:
                        content = f.read()
                        template_content[full_path] = content
                        
                        # Ø­Ø³Ø§Ø¨ hash Ù„Ù„Ù…Ø­ØªÙˆÙ‰ (ØªØ¬Ø§Ù‡Ù„ Ø§Ù„Ù…Ø³Ø§ÙØ§Øª)
                        normalized = re.sub(r'\s+', ' ', content.strip())
                        content_hash = hash(normalized)
                        content_hashes[content_hash].append(full_path)
                except Exception as e:
                    print(f"Ø®Ø·Ø£ ÙÙŠ Ù‚Ø±Ø§Ø¡Ø© {full_path}: {e}")
    
    # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ù…Ø­ØªÙˆÙ‰ Ù…Ø·Ø§Ø¨Ù‚ ØªÙ…Ø§Ù…Ø§Ù‹
    exact_duplicates = {h: paths for h, paths in content_hashes.items() if len(paths) > 1}
    
    if exact_duplicates:
        print("\nâš ï¸ Ù‚ÙˆØ§Ù„Ø¨ Ø¨Ù…Ø­ØªÙˆÙ‰ Ù…Ø·Ø§Ø¨Ù‚:")
        for content_hash, paths in exact_duplicates.items():
            print(f"  Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ù…ØªØ·Ø§Ø¨Ù‚:")
            for path in paths:
                print(f"    - {path}")
    
    return exact_duplicates

def analyze_function_names():
    """ØªØ­Ù„ÙŠÙ„ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø¯ÙˆØ§Ù„ Ø§Ù„Ù…ÙƒØ±Ø±Ø©"""
    print("\n=== ØªØ­Ù„ÙŠÙ„ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø¯ÙˆØ§Ù„ ===")
    
    with open('routes.py', 'r', encoding='utf-8') as f:
        content = f.read()
    
    # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø¬Ù…ÙŠØ¹ ØªØ¹Ø±ÙŠÙØ§Øª Ø§Ù„Ø¯ÙˆØ§Ù„
    function_pattern = r"def\s+(\w+)\s*\("
    matches = re.findall(function_pattern, content)
    
    function_counts = defaultdict(int)
    for func in matches:
        function_counts[func] += 1
    
    duplicates = {name: count for name, count in function_counts.items() if count > 1}
    
    if duplicates:
        print("\nâš ï¸ Ø£Ø³Ù…Ø§Ø¡ Ø¯ÙˆØ§Ù„ Ù…ÙƒØ±Ø±Ø©:")
        for name, count in duplicates.items():
            print(f"  {name}: {count} Ù…Ø±Ø©")
    
    return duplicates

def check_route_function_mapping():
    """ÙØ­Øµ ØªØ·Ø§Ø¨Ù‚ Ø§Ù„Ù…Ø³Ø§Ø±Ø§Øª Ù…Ø¹ Ø§Ù„Ø¯ÙˆØ§Ù„"""
    print("\n=== ÙØ­Øµ ØªØ·Ø§Ø¨Ù‚ Ø§Ù„Ù…Ø³Ø§Ø±Ø§Øª Ù…Ø¹ Ø§Ù„Ø¯ÙˆØ§Ù„ ===")
    
    with open('routes.py', 'r', encoding='utf-8') as f:
        content = f.read()
    
    # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ù…Ø³Ø§Ø±Ø§Øª ÙˆØ§Ù„Ø¯ÙˆØ§Ù„ Ø§Ù„Ù…Ø±ØªØ¨Ø·Ø©
    route_function_pattern = r"@app\.route\(['\"]([^'\"]+)['\"](?:[^)]+)?\)\s*(?:@[\w_]+\s*)*\ndef\s+(\w+)"
    matches = re.findall(route_function_pattern, content, re.MULTILINE | re.DOTALL)
    
    route_to_functions = defaultdict(list)
    function_to_routes = defaultdict(list)
    
    for route, function in matches:
        route_to_functions[route].append(function)
        function_to_routes[function].append(route)
    
    # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ù…Ø³Ø§Ø±Ø§Øª Ù…Ø¹ Ø¯ÙˆØ§Ù„ Ù…ØªØ¹Ø¯Ø¯Ø©
    multi_function_routes = {route: funcs for route, funcs in route_to_functions.items() if len(funcs) > 1}
    
    if multi_function_routes:
        print("\nâš ï¸ Ù…Ø³Ø§Ø±Ø§Øª Ù…Ø¹ Ø¯ÙˆØ§Ù„ Ù…ØªØ¹Ø¯Ø¯Ø©:")
        for route, functions in multi_function_routes.items():
            print(f"  {route}: {', '.join(functions)}")
    
    # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø¯ÙˆØ§Ù„ Ù…Ø¹ Ù…Ø³Ø§Ø±Ø§Øª Ù…ØªØ¹Ø¯Ø¯Ø©
    multi_route_functions = {func: routes for func, routes in function_to_routes.items() if len(routes) > 1}
    
    if multi_route_functions:
        print("\nâš ï¸ Ø¯ÙˆØ§Ù„ Ù…Ø¹ Ù…Ø³Ø§Ø±Ø§Øª Ù…ØªØ¹Ø¯Ø¯Ø©:")
        for function, routes in multi_route_functions.items():
            print(f"  {function}: {', '.join(routes)}")
    
    return multi_function_routes, multi_route_functions

def main():
    print("ğŸ” ÙØ­Øµ Ø§Ù„Ù…Ø´Ø±ÙˆØ¹ Ù„Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø§Ù„ØªÙƒØ±Ø§Ø± ÙˆØ§Ù„ØªØ¶Ø§Ø±Ø¨\n")
    
    # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø³Ø§Ø±Ø§Øª
    routes, duplicate_routes, similar_routes = analyze_routes()
    
    # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù‚ÙˆØ§Ù„Ø¨
    template_files, template_duplicates = analyze_templates()
    
    # ØªØ­Ù„ÙŠÙ„ Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù‚ÙˆØ§Ù„Ø¨
    content_duplicates = analyze_template_content()
    
    # ØªØ­Ù„ÙŠÙ„ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø¯ÙˆØ§Ù„
    function_duplicates = analyze_function_names()
    
    # ÙØ­Øµ ØªØ·Ø§Ø¨Ù‚ Ø§Ù„Ù…Ø³Ø§Ø±Ø§Øª ÙˆØ§Ù„Ø¯ÙˆØ§Ù„
    multi_function_routes, multi_route_functions = check_route_function_mapping()
    
    # Ù…Ù„Ø®Øµ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
    print("\n" + "="*50)
    print("ğŸ“Š Ù…Ù„Ø®Øµ Ø§Ù„ØªØ­Ù„ÙŠÙ„:")
    
    issues_found = 0
    
    if duplicate_routes:
        print(f"âš ï¸ {len(duplicate_routes)} Ù…Ø³Ø§Ø± Ù…ÙƒØ±Ø±")
        issues_found += len(duplicate_routes)
    
    if similar_routes:
        print(f"âš ï¸ {len(similar_routes)} Ù…Ø³Ø§Ø± Ù…ØªØ´Ø§Ø¨Ù‡")
        issues_found += len(similar_routes)
    
    if template_duplicates:
        print(f"âš ï¸ {len(template_duplicates)} Ø§Ø³Ù… Ù‚Ø§Ù„Ø¨ Ù…ÙƒØ±Ø±")
        issues_found += len(template_duplicates)
    
    if content_duplicates:
        print(f"âš ï¸ {len(content_duplicates)} Ù‚Ø§Ù„Ø¨ Ø¨Ù…Ø­ØªÙˆÙ‰ Ù…Ø·Ø§Ø¨Ù‚")
        issues_found += len(content_duplicates)
    
    if function_duplicates:
        print(f"âš ï¸ {len(function_duplicates)} Ø§Ø³Ù… Ø¯Ø§Ù„Ø© Ù…ÙƒØ±Ø±")
        issues_found += len(function_duplicates)
    
    if multi_function_routes:
        print(f"âš ï¸ {len(multi_function_routes)} Ù…Ø³Ø§Ø± Ù…Ø¹ Ø¯ÙˆØ§Ù„ Ù…ØªØ¹Ø¯Ø¯Ø©")
        issues_found += len(multi_function_routes)
    
    if multi_route_functions:
        print(f"âš ï¸ {len(multi_route_functions)} Ø¯Ø§Ù„Ø© Ù…Ø¹ Ù…Ø³Ø§Ø±Ø§Øª Ù…ØªØ¹Ø¯Ø¯Ø©")
        issues_found += len(multi_route_functions)
    
    if issues_found == 0:
        print("âœ… Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ø´Ø§ÙƒÙ„ ØªÙƒØ±Ø§Ø± ÙˆØ§Ø¶Ø­Ø©")
    else:
        print(f"\nğŸš¨ Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ù…Ø´Ø§ÙƒÙ„ Ø§Ù„Ù…Ø­ØªÙ…Ù„Ø©: {issues_found}")
        print("ÙŠÙÙ†ØµØ­ Ø¨Ù…Ø±Ø§Ø¬Ø¹Ø© Ù‡Ø°Ù‡ Ø§Ù„Ù†Ù‚Ø§Ø· Ù„ØªØ¬Ù†Ø¨ Ø§Ù„ØªØ¶Ø§Ø±Ø¨")

if __name__ == "__main__":
    main()