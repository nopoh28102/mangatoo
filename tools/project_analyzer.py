#!/usr/bin/env python3
"""
Ø£Ø¯Ø§Ø© ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø±ÙˆØ¹ Ø§Ù„Ø´Ø§Ù…Ù„Ø© - ØªØ­Ù„ÙŠÙ„ Ø¹Ù…ÙŠÙ‚ Ù„Ù…Ø´Ø±ÙˆØ¹ Ù…Ù†ØµØ© Ø§Ù„Ù…Ø§Ù†Ø¬Ø§
Deep Project Analysis Tool for Manga Platform
"""

import os
import sys
import json
import sqlite3
import logging
from datetime import datetime
from collections import defaultdict, Counter
import re

# Ø¥Ø¹Ø¯Ø§Ø¯ Ù†Ø¸Ø§Ù… Ø§Ù„Ø³Ø¬Ù„Ø§Øª
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class ProjectAnalyzer:
    """Ù…Ø­Ù„Ù„ Ø´Ø§Ù…Ù„ Ù„Ù„Ù…Ø´Ø±ÙˆØ¹"""
    
    def __init__(self, project_root="."):
        self.project_root = project_root
        self.analysis_results = {}
        self.db_path = os.path.join(project_root, "manga_platform.db")
        
    def analyze_all(self):
        """ØªØ­Ù„ÙŠÙ„ Ø´Ø§Ù…Ù„ Ù„Ù„Ù…Ø´Ø±ÙˆØ¹"""
        print("ğŸ” Ø¨Ø¯Ø¡ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø´Ø§Ù…Ù„ Ù„Ù„Ù…Ø´Ø±ÙˆØ¹...")
        
        self.analysis_results = {
            'timestamp': datetime.now().isoformat(),
            'project_structure': self.analyze_structure(),
            'database_analysis': self.analyze_database(),
            'code_metrics': self.analyze_code(),
            'dependencies': self.analyze_dependencies(),
            'security_analysis': self.security_scan(),
            'performance_metrics': self.performance_analysis(),
            'recommendations': self.generate_recommendations()
        }
        
        return self.analysis_results
    
    def analyze_structure(self):
        """ØªØ­Ù„ÙŠÙ„ Ù‡ÙŠÙƒÙ„ Ø§Ù„Ù…Ø´Ø±ÙˆØ¹"""
        structure = {
            'total_files': 0,
            'directories': [],
            'file_types': Counter(),
            'large_files': [],
            'empty_files': []
        }
        
        for root, dirs, files in os.walk(self.project_root):
            # ØªØ¬Ø§Ù‡Ù„ Ù…Ø¬Ù„Ø¯Ø§Øª Ø§Ù„Ù†Ø¸Ø§Ù…
            dirs[:] = [d for d in dirs if not d.startswith('.') and d != '__pycache__']
            
            for d in dirs:
                structure['directories'].append(os.path.join(root, d))
                
            for file in files:
                if file.startswith('.'):
                    continue
                    
                filepath = os.path.join(root, file)
                structure['total_files'] += 1
                
                # ØªØ­Ù„ÙŠÙ„ Ù†ÙˆØ¹ Ø§Ù„Ù…Ù„Ù
                ext = os.path.splitext(file)[1].lower()
                structure['file_types'][ext] += 1
                
                # ØªØ­Ù„ÙŠÙ„ Ø­Ø¬Ù… Ø§Ù„Ù…Ù„Ù
                try:
                    size = os.path.getsize(filepath)
                    if size > 1024 * 1024:  # Ø£ÙƒØ¨Ø± Ù…Ù† 1MB
                        structure['large_files'].append({
                            'path': filepath,
                            'size_mb': round(size / (1024 * 1024), 2)
                        })
                    elif size == 0:
                        structure['empty_files'].append(filepath)
                except OSError:
                    pass
        
        return structure
    
    def analyze_database(self):
        """ØªØ­Ù„ÙŠÙ„ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
        if not os.path.exists(self.db_path):
            return {'error': 'Database file not found'}
        
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            analysis = {
                'tables': {},
                'total_records': 0,
                'indexes': [],
                'foreign_keys': [],
                'largest_tables': []
            }
            
            # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„
            cursor.execute("SELECT name FROM sqlite_master WHERE type='table'")
            tables = [row[0] for row in cursor.fetchall()]
            
            for table in tables:
                # Ø¹Ø¯Ø¯ Ø§Ù„Ø³Ø¬Ù„Ø§Øª - using proper identifier quoting
                quoted_table = f'"{table.replace('"', '""')}"'
                cursor.execute(f"SELECT COUNT(*) FROM {quoted_table}")
                count = cursor.fetchone()[0]
                analysis['total_records'] += count
                
                # Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©
                cursor.execute("PRAGMA table_info(?)", (table,))
                columns = cursor.fetchall()
                
                # Ø§Ù„ÙÙ‡Ø§Ø±Ø³
                cursor.execute("PRAGMA index_list(?)", (table,))
                indexes = cursor.fetchall()
                
                # Ø§Ù„Ù…ÙØ§ØªÙŠØ­ Ø§Ù„Ø®Ø§Ø±Ø¬ÙŠØ©
                cursor.execute("PRAGMA foreign_key_list(?)", (table,))
                foreign_keys = cursor.fetchall()
                
                analysis['tables'][table] = {
                    'row_count': count,
                    'columns': len(columns),
                    'column_details': [{'name': col[1], 'type': col[2], 'not_null': bool(col[3])} for col in columns],
                    'indexes': len(indexes),
                    'foreign_keys': len(foreign_keys)
                }
                
                if count > 0:
                    analysis['largest_tables'].append({'table': table, 'count': count})
            
            # ØªØ±ØªÙŠØ¨ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ Ø­Ø³Ø¨ Ø§Ù„Ø¹Ø¯Ø¯
            analysis['largest_tables'].sort(key=lambda x: x['count'], reverse=True)
            
            conn.close()
            return analysis
            
        except Exception as e:
            return {'error': f'Database analysis failed: {str(e)}'}
    
    def analyze_code(self):
        """ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙƒÙˆØ¯"""
        code_metrics = {
            'python_files': 0,
            'total_lines': 0,
            'functions': 0,
            'classes': 0,
            'routes': 0,
            'imports': Counter(),
            'complexity_issues': []
        }
        
        python_files = []
        for root, dirs, files in os.walk(self.project_root):
            dirs[:] = [d for d in dirs if not d.startswith('.') and d != '__pycache__']
            for file in files:
                if file.endswith('.py'):
                    python_files.append(os.path.join(root, file))
        
        for py_file in python_files:
            try:
                with open(py_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                    lines = content.split('\n')
                    
                code_metrics['python_files'] += 1
                code_metrics['total_lines'] += len(lines)
                
                # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¯ÙˆØ§Ù„ ÙˆØ§Ù„ÙƒÙ„Ø§Ø³Ø§Øª
                code_metrics['functions'] += len(re.findall(r'^def\s+\w+', content, re.MULTILINE))
                code_metrics['classes'] += len(re.findall(r'^class\s+\w+', content, re.MULTILINE))
                
                # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø·Ø±Ù‚ (Routes)
                code_metrics['routes'] += len(re.findall(r'@app\.route\(', content))
                
                # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§Ø³ØªÙŠØ±Ø§Ø¯
                imports = re.findall(r'^(?:from\s+(\S+)\s+)?import\s+(.+)', content, re.MULTILINE)
                for from_module, import_items in imports:
                    if from_module:
                        code_metrics['imports'][from_module] += 1
                    else:
                        for item in import_items.split(','):
                            code_metrics['imports'][item.strip()] += 1
                
                # ÙØ­Øµ Ø§Ù„ØªØ¹Ù‚ÙŠØ¯
                if len(lines) > 1000:
                    code_metrics['complexity_issues'].append({
                        'file': py_file,
                        'issue': 'Large file',
                        'lines': len(lines)
                    })
                
            except Exception as e:
                logger.warning(f"Could not analyze {py_file}: {e}")
        
        return code_metrics
    
    def analyze_dependencies(self):
        """ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªØ¨Ø¹ÙŠØ§Øª"""
        deps = {
            'python_packages': [],
            'outdated_packages': [],
            'security_vulnerabilities': []
        }
        
        # Ù‚Ø±Ø§Ø¡Ø© pyproject.toml
        pyproject_path = os.path.join(self.project_root, 'pyproject.toml')
        if os.path.exists(pyproject_path):
            try:
                with open(pyproject_path, 'r') as f:
                    content = f.read()
                    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ØªØ¨Ø¹ÙŠØ§Øª
                    deps_section = re.search(r'dependencies\s*=\s*\[(.*?)\]', content, re.DOTALL)
                    if deps_section:
                        deps_text = deps_section.group(1)
                        packages = re.findall(r'"([^"]+)"', deps_text)
                        deps['python_packages'] = packages
            except Exception as e:
                logger.warning(f"Could not parse pyproject.toml: {e}")
        
        return deps
    
    def security_scan(self):
        """ÙØ­Øµ Ø§Ù„Ø£Ù…Ø§Ù†"""
        security = {
            'issues': [],
            'best_practices': [],
            'recommendations': []
        }
        
        # ÙØ­Øµ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ø­Ø³Ø§Ø³Ø©
        sensitive_files = ['.env', 'config.py', 'secrets.txt']
        for file in sensitive_files:
            if os.path.exists(os.path.join(self.project_root, file)):
                security['issues'].append(f'Sensitive file found: {file}')
        
        # ÙØ­Øµ ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…Ø±ÙˆØ± Ø§Ù„Ù…ÙØ«Ø¨ØªØ© ÙÙŠ Ø§Ù„ÙƒÙˆØ¯
        python_files = []
        for root, dirs, files in os.walk(self.project_root):
            dirs[:] = [d for d in dirs if not d.startswith('.') and d != '__pycache__']
            for file in files:
                if file.endswith('.py'):
                    python_files.append(os.path.join(root, file))
        
        password_patterns = [
            r'password\s*=\s*["\'][^"\']+["\']',
            r'secret\s*=\s*["\'][^"\']+["\']',
            r'api_key\s*=\s*["\'][^"\']+["\']'
        ]
        
        for py_file in python_files:
            try:
                with open(py_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                    for pattern in password_patterns:
                        matches = re.findall(pattern, content, re.IGNORECASE)
                        if matches and 'admin123' not in content:  # ØªØ¬Ø§Ù‡Ù„ ÙƒÙ„Ù…Ø© Ù…Ø±ÙˆØ± Ø§Ù„Ù…Ø´Ø±Ù Ø§Ù„ØªØ¬Ø±ÙŠØ¨ÙŠØ©
                            security['issues'].append(f'Hardcoded credential in {py_file}')
            except:
                pass
        
        # ÙØ­Øµ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø£Ù…Ø§Ù† ÙÙŠ Flask
        security['best_practices'] = [
            'Use environment variables for secrets',
            'Enable CSRF protection',
            'Use HTTPS in production',
            'Validate all user inputs',
            'Implement rate limiting'
        ]
        
        return security
    
    def performance_analysis(self):
        """ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø¯Ø§Ø¡"""
        performance = {
            'database_queries': 0,
            'large_files': [],
            'optimization_opportunities': []
        }
        
        # ÙØ­Øµ Ø§Ø³ØªØ¹Ù„Ø§Ù…Ø§Øª Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        python_files = []
        for root, dirs, files in os.walk(self.project_root):
            dirs[:] = [d for d in dirs if not d.startswith('.') and d != '__pycache__']
            for file in files:
                if file.endswith('.py'):
                    python_files.append(os.path.join(root, file))
        
        for py_file in python_files:
            try:
                with open(py_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                    # Ø¹Ø¯Ø¯ Ø§Ø³ØªØ¹Ù„Ø§Ù…Ø§Øª Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
                    queries = len(re.findall(r'\.query\.|\.execute\(|\.filter\(', content))
                    performance['database_queries'] += queries
                    
                    # ÙØ­Øµ Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù…Ø§Øª Ø§Ù„Ù…Ø¹Ù‚Ø¯Ø©
                    if 'join(' in content.lower():
                        performance['optimization_opportunities'].append(f'Complex joins in {py_file}')
                    
                    if '.all()' in content and '.filter(' in content:
                        performance['optimization_opportunities'].append(f'Potential N+1 query in {py_file}')
                        
            except:
                pass
        
        return performance
    
    def generate_recommendations(self):
        """ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØªÙˆØµÙŠØ§Øª"""
        recommendations = {
            'immediate_actions': [],
            'performance_improvements': [],
            'security_enhancements': [],
            'code_quality': []
        }
        
        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙˆØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØªÙˆØµÙŠØ§Øª
        if self.analysis_results.get('code_metrics', {}).get('total_lines', 0) > 10000:
            recommendations['code_quality'].append('Consider breaking large files into smaller modules')
        
        if self.analysis_results.get('database_analysis', {}).get('total_records', 0) > 10000:
            recommendations['performance_improvements'].append('Consider database indexing optimization')
        
        if self.analysis_results.get('security_analysis', {}).get('issues'):
            recommendations['security_enhancements'].append('Address security vulnerabilities immediately')
        
        recommendations['immediate_actions'] = [
            'Update all dependencies to latest versions',
            'Run comprehensive tests',
            'Review and update documentation'
        ]
        
        return recommendations
    
    def generate_report(self, output_file='project_analysis_report.json'):
        """ØªÙˆÙ„ÙŠØ¯ ØªÙ‚Ø±ÙŠØ± Ø´Ø§Ù…Ù„"""
        results = self.analyze_all()
        
        # Ø­ÙØ¸ Ø§Ù„ØªÙ‚Ø±ÙŠØ±
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False, default=str)
        
        print(f"ğŸ“Š ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØªÙ‚Ø±ÙŠØ±: {output_file}")
        
        # Ø·Ø¨Ø§Ø¹Ø© Ù…Ù„Ø®Øµ
        self.print_summary(results)
        
        return results
    
    def print_summary(self, results):
        """Ø·Ø¨Ø§Ø¹Ø© Ù…Ù„Ø®Øµ Ø§Ù„ØªØ­Ù„ÙŠÙ„"""
        print("\n" + "="*60)
        print("ğŸ“‹ Ù…Ù„Ø®Øµ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø±ÙˆØ¹")
        print("="*60)
        
        # Ù‡ÙŠÙƒÙ„ Ø§Ù„Ù…Ø´Ø±ÙˆØ¹
        structure = results.get('project_structure', {})
        print(f"ğŸ“ Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ù…Ù„ÙØ§Øª: {structure.get('total_files', 0)}")
        print(f"ğŸ“‚ Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª: {len(structure.get('directories', []))}")
        
        # Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        db_analysis = results.get('database_analysis', {})
        if 'error' not in db_analysis:
            print(f"ğŸ—„ï¸  Ø¬Ø¯Ø§ÙˆÙ„ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {len(db_analysis.get('tables', {}))}")
            print(f"ğŸ“Š Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø³Ø¬Ù„Ø§Øª: {db_analysis.get('total_records', 0)}")
        
        # Ø§Ù„ÙƒÙˆØ¯
        code = results.get('code_metrics', {})
        print(f"ğŸ Ù…Ù„ÙØ§Øª Python: {code.get('python_files', 0)}")
        print(f"ğŸ“ Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø£Ø³Ø·Ø±: {code.get('total_lines', 0)}")
        print(f"ğŸ”€ Ø§Ù„Ø·Ø±Ù‚ (Routes): {code.get('routes', 0)}")
        
        # Ø§Ù„Ø£Ù…Ø§Ù†
        security = results.get('security_analysis', {})
        issues_count = len(security.get('issues', []))
        print(f"ğŸ”’ Ù…Ø´Ø§ÙƒÙ„ Ø§Ù„Ø£Ù…Ø§Ù†: {issues_count}")
        
        # Ø§Ù„ØªÙˆØµÙŠØ§Øª
        recommendations = results.get('recommendations', {})
        total_recommendations = sum(len(recommendations.get(key, [])) for key in recommendations)
        print(f"ğŸ’¡ Ø§Ù„ØªÙˆØµÙŠØ§Øª: {total_recommendations}")
        
        print("="*60)

def main():
    """Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©"""
    analyzer = ProjectAnalyzer()
    
    print("ğŸš€ Ù…Ø±Ø­Ø¨Ø§Ù‹ Ø¨Ùƒ ÙÙŠ Ø£Ø¯Ø§Ø© ØªØ­Ù„ÙŠÙ„ Ù…Ø´Ø±ÙˆØ¹ Ù…Ù†ØµØ© Ø§Ù„Ù…Ø§Ù†Ø¬Ø§!")
    print("Ù‡Ø°Ù‡ Ø§Ù„Ø£Ø¯Ø§Ø© Ø³ØªÙ‚ÙˆÙ… Ø¨ØªØ­Ù„ÙŠÙ„ Ø´Ø§Ù…Ù„ Ù„Ù„Ù…Ø´Ø±ÙˆØ¹ ÙˆØªÙ‚Ø¯ÙŠÙ… ØªÙ‚Ø±ÙŠØ± Ù…ÙØµÙ„.")
    
    try:
        results = analyzer.generate_report()
        print("âœ… ØªÙ… Ø§Ù„Ø§Ù†ØªÙ‡Ø§Ø¡ Ù…Ù† Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø¨Ù†Ø¬Ø§Ø­!")
        
    except Exception as e:
        print(f"âŒ Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„ØªØ­Ù„ÙŠÙ„: {e}")
        logger.error(f"Analysis failed: {e}")

if __name__ == "__main__":
    main()