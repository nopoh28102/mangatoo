"""
Ù…Ø¹Ø§Ù„Ø¬ ÙƒØ´Ø· Ø§Ù„ØµÙˆØ± Ù„Ù„Ù…ÙˆØ§Ù‚Ø¹ Ø§Ù„Ù…Ø®ØªÙ„ÙØ©
ÙŠØ­Ù„ Ù…Ø´ÙƒÙ„Ø© Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ØµÙˆØ± Ø§Ù„Ù…ÙƒØ´ÙˆØ·Ø© ÙÙŠ Ø§Ù„Ù†Ø¸Ø§Ù…
"""
import os

def check_scraped_images():
    """
    ÙØ­Øµ Ø§Ù„ØµÙˆØ± Ø§Ù„Ù…ÙƒØ´ÙˆØ·Ø© ÙÙŠ Ø§Ù„Ù…Ø¬Ù„Ø¯ Ø§Ù„Ù…Ø¤Ù‚Øª
    Ø¥Ø±Ø¬Ø§Ø¹: Ù‚Ø§Ø¦Ù…Ø© Ø¨Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„ØµÙˆØ± Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø©
    """
    temp_scraped_dir = os.path.join('static', 'uploads', 'temp_scraped')
    scraped_images = []
    
    try:
        if os.path.exists(temp_scraped_dir):
            all_files = os.listdir(temp_scraped_dir)
            scraped_images = [
                f for f in all_files 
                if f.lower().endswith(('.jpg', '.jpeg', '.png', '.webp', '.gif'))
                and os.path.isfile(os.path.join(temp_scraped_dir, f))
            ]
            print(f"ğŸ” ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ {len(scraped_images)} ØµÙˆØ±Ø© Ù…ÙƒØ´ÙˆØ·Ø© ÙÙŠ Ø§Ù„Ù…Ø¬Ù„Ø¯ Ø§Ù„Ù…Ø¤Ù‚Øª")
            for img in scraped_images[:5]:  # Ø¹Ø±Ø¶ Ø£ÙˆÙ„ 5 ØµÙˆØ±
                print(f"  - {img}")
        else:
            print("ğŸ“‚ Ø§Ù„Ù…Ø¬Ù„Ø¯ Ø§Ù„Ù…Ø¤Ù‚Øª Ù„Ù„ØµÙˆØ± Ø§Ù„Ù…ÙƒØ´ÙˆØ·Ø© ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯")
            
    except Exception as e:
        print(f"âš ï¸ Ø®Ø·Ø£ ÙÙŠ ÙØ­Øµ Ø§Ù„ØµÙˆØ± Ø§Ù„Ù…ÙƒØ´ÙˆØ·Ø©: {e}")
        scraped_images = []
    
    return scraped_images

def perform_olympus_scraping(chapter_url):
    """
    ÙƒØ´Ø· Ù…Ø¨Ø§Ø´Ø± Ù…Ù† Ù…ÙˆÙ‚Ø¹ OlympusStaff
    """
    temp_scraped_dir = os.path.join('static', 'uploads', 'temp_scraped')
    
    try:
        # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ø¬Ù„Ø¯ ÙˆØªÙ†Ø¸ÙŠÙÙ‡
        os.makedirs(temp_scraped_dir, exist_ok=True)
        
        # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù…Ø¬Ù„Ø¯ Ù…Ù† Ø§Ù„ØµÙˆØ± Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©
        for file in os.listdir(temp_scraped_dir):
            file_path = os.path.join(temp_scraped_dir, file)
            if os.path.isfile(file_path):
                os.remove(file_path)
        
        print(f"ğŸ“¥ Ø¨Ø¯Ø¡ ÙƒØ´Ø· Ø§Ù„ØµÙˆØ± Ù…Ù† OlympusStaff: {chapter_url}")
        
        # ÙƒØ´Ø· Ø§Ù„ØµÙˆØ±
        from olympustaff_scraper import scrape_olympustaff_enhanced, download_olympustaff_images
        scrape_result = scrape_olympustaff_enhanced(chapter_url)
        
        if scrape_result['success'] and scrape_result['images']:
            downloaded_images = download_olympustaff_images(
                scrape_result['images'], 
                temp_scraped_dir, 
                chapter_url
            )
            
            print(f"âœ… ØªÙ… ÙƒØ´Ø· ÙˆØ­ÙØ¸ {len(downloaded_images)} ØµÙˆØ±Ø© Ø¨Ù†Ø¬Ø§Ø­")
            return {
                'success': True,
                'images_count': len(downloaded_images),
                'chapter_title': scrape_result.get('chapter_title', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯'),
                'message': f'ØªÙ… Ø­ÙØ¸ {len(downloaded_images)} ØµÙˆØ±Ø©'
            }
        else:
            error_msg = scrape_result.get('error', 'Ø®Ø·Ø£ ØºÙŠØ± Ù…Ø­Ø¯Ø¯ ÙÙŠ Ø§Ù„ÙƒØ´Ø·')
            print(f"âŒ ÙØ´Ù„ ÙÙŠ ÙƒØ´Ø· Ø§Ù„ØµÙˆØ±: {error_msg}")
            return {
                'success': False,
                'error': error_msg
            }
            
    except Exception as e:
        error_msg = f"Ø®Ø·Ø£ ÙÙŠ Ø¹Ù…Ù„ÙŠØ© Ø§Ù„ÙƒØ´Ø·: {str(e)}"
        print(f"âŒ Ø®Ø·Ø£ ÙÙŠ perform_olympus_scraping: {error_msg}")
        return {
            'success': False,
            'error': error_msg
        }

def validate_scraped_images_for_upload():
    """
    Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ø§Ù„ØµÙˆØ± Ø§Ù„Ù…ÙƒØ´ÙˆØ·Ø© Ù„Ù„Ø±ÙØ¹
    """
    scraped_images = check_scraped_images()
    
    if not scraped_images:
        return {
            'valid': False,
            'message': 'Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ ØµÙˆØ± Ù…ÙƒØ´ÙˆØ·Ø©. ÙŠØ±Ø¬Ù‰ ÙƒØ´Ø· Ø§Ù„ØµÙˆØ± Ø£ÙˆÙ„Ø§Ù‹.',
            'images_count': 0
        }
    
    return {
        'valid': True,
        'message': f'ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ {len(scraped_images)} ØµÙˆØ±Ø© Ø¬Ø§Ù‡Ø²Ø© Ù„Ù„Ø±ÙØ¹',
        'images_count': len(scraped_images),
        'images': scraped_images
    }